{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fatigue Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "#Necessary Imports\n",
    "from scipy.spatial import distance\n",
    "from imutils import face_utils\n",
    "from statistics import mean\n",
    "from pygame import mixer\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.3  #The deafult EAR value below which an eye is considered closed, in case calibration fails\n",
    "frameLimit = 30  #Number of frames eye can be closed before warning triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "faceDetector = dlib.get_frontal_face_detector() #Initialize pre-trained face detector\n",
    "shapePredictor = dlib.shape_predictor(\"facialLandmarkShapePredictor_68pt.dat\") #Loads facial landmark predictor\n",
    "\n",
    "#First and last points of the landmark shape predictor (LSP) that describe each feature\n",
    "(L_eyeStart, L_eyeEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(R_eyeStart, R_eyeEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "#Initialize sounds\n",
    "mixer.init()\n",
    "alarm = mixer.Sound('beep.wav')\n",
    "focus = mixer.Sound('focus16bit.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('mouth', (48, 68)),\n",
       "             ('inner_mouth', (60, 68)),\n",
       "             ('right_eyebrow', (17, 22)),\n",
       "             ('left_eyebrow', (22, 27)),\n",
       "             ('right_eye', (36, 42)),\n",
       "             ('left_eye', (42, 48)),\n",
       "             ('nose', (27, 36)),\n",
       "             ('jaw', (0, 17))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_utils.FACIAL_LANDMARKS_IDXS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input: eye_pts - a numpy array of 6 x,y co-ordinate pairs that make up the shape of the eye as per the LSP\n",
    "#Returns: EAR   - a 64-bit float representing the eye's aspect ratio.\n",
    "def calculate_EyeAspectRatio(eye_pts):\n",
    "    #Vertical components\n",
    "    X = distance.euclidean(eye_pts[1], eye_pts[5])\n",
    "    Y = distance.euclidean(eye_pts[2], eye_pts[4])\n",
    "    #Horizontal component\n",
    "    Z = distance.euclidean(eye_pts[0], eye_pts[3])\n",
    "    \n",
    "    EAR = (X + Y) / (2.0 * Z)\n",
    "    return EAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wakeDriver(frame):\n",
    "    alarm.play()\n",
    "    cv2.rectangle(frame,(0,0),(600,327),(0,0,255),20) #Red boarder\n",
    "    cv2.putText(frame, \"WAKE UP!\", (225, 40),cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"EMERGENCY\", (210, 310),cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alertDriver(frame, driverAlerted):\n",
    "    if not driverAlerted:\n",
    "        focus.play()\n",
    "    cv2.putText(frame, \"Face Not Detected...\", (150, 165),cv2.FONT_HERSHEY_COMPLEX, 1, (100, 100, 200), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0) #Video Input w/ OpenCV\n",
    "frameCount = 0            #Tracks how long eyes have been closed\n",
    "driving = True\n",
    "speed = 72                #Current Vehicle speed\n",
    "minimumSpeed = 30         #Speed at which the Fatigue Prevention system activates\n",
    "undetectedDuration = 0    #Monitors how long a face has gone undetected for\n",
    "driverAlerted = False\n",
    "\n",
    "#The variables below are concerned with calculating user-specific threshold EAR values at which alarm is triggered\n",
    "calibrationEARs = []        #List containing first user EAR values to be averaged\n",
    "currentFrame = 0            #Frame counter, for time keeping\n",
    "calibrationDuration = 40    #Duration (frames) of the calibration period\n",
    "thresholdPercentage = 0.75  #Percentage of resting EAR to set threshold at\n",
    "thresholdCalculated = False \n",
    "\n",
    "while driving and speed > minimumSpeed:\n",
    "    #Exctract frame + preprocess\n",
    "    _, frame = cam.read() #Grabs the current frame of the camera feed\n",
    "    frame = imutils.resize(frame, width=600)       #Resizes\n",
    "    grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Greyscale\n",
    "    \n",
    "    #Detect faces within grescale image\n",
    "    faces = faceDetector(grey,1)\n",
    "    \n",
    "    #Triggers one-time gentle Alert if no face detected for short period of time\n",
    "    if len(faces) == 0:\n",
    "        undetectedDuration += 1\n",
    "        if undetectedDuration > frameLimit:\n",
    "            alertDriver(frame, driverAlerted)\n",
    "            driverAlerted = True\n",
    "    else:\n",
    "        undetectedDuration = 0\n",
    "        driverAlerted = False\n",
    "    \n",
    "    \n",
    "    for face in faces:\n",
    "        #Determine facial landmarks for face ROI, then convert co-ords to NumPy array\n",
    "        shape = shapePredictor(grey, face)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        #Draw bounding box around detected face\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(face) #convert dlib rect to openCV bounding box\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (100,100,100),1)\n",
    "        \n",
    "        cv2.putText(frame,\"Driver\", (x-5, y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5, (100,100,100),1)\n",
    "        \n",
    "        #Define set of points (from LSP) that constitutes each feature\n",
    "        left_eye = shape[L_eyeStart:L_eyeEnd]\n",
    "        right_eye = shape[R_eyeStart:R_eyeEnd]\n",
    "        \n",
    "        #Calculate Eye Aspect Ratio for each eye\n",
    "        left_EAR = calculate_EyeAspectRatio(left_eye)\n",
    "        right_EAR = calculate_EyeAspectRatio(right_eye)\n",
    "        EAR = (left_EAR + right_EAR) / 2.0  #Take Average\n",
    "        \n",
    "        cv2.putText(frame, \"EAR: {:.2f}\".format(EAR), (15,310),cv2.FONT_HERSHEY_SIMPLEX,0.85, (100,100,100),2)\n",
    "        \n",
    "        try:\n",
    "            #Calibrate EAR threshold values to user\n",
    "            if currentFrame < calibrationDuration:\n",
    "                cv2.putText(frame, \"Calibrating...\", (15,280),cv2.FONT_HERSHEY_SIMPLEX,0.5, (0,0,255),1)\n",
    "                calibrationEARs.append(EAR)\n",
    "            elif thresholdCalculated == False:\n",
    "                threshold = mean(calibrationEARs) * thresholdPercentage\n",
    "                cv2.putText(frame, \"Threshold: {:.2f}\".format(threshold), (15,280),cv2.FONT_HERSHEY_SIMPLEX,0.5, (100,100,200),1)\n",
    "                thresholdCalculated == True\n",
    "        except:\n",
    "            cv2.putText(frame, \"Face unable to be detected upon launch - using default EAR threshold\", \n",
    "                        (15,280),cv2.FONT_HERSHEY_SIMPLEX,0.5, (100,100,255),1)\n",
    "        \n",
    "        #Use OpenCV to draw eye contours\n",
    "        leftEyeHull = cv2.convexHull(left_eye)\n",
    "        rightEyeHull = cv2.convexHull(right_eye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "        \n",
    "        \n",
    "        #Detects when EAR falls below calculated threshold\n",
    "        if EAR < threshold:\n",
    "            frameCount += 1\n",
    "            #print(frameCount)\n",
    "            if frameCount >= frameLimit:\n",
    "                #If the driver is asleep, we wake them up\n",
    "                wakeDriver(frame)\n",
    "        else:\n",
    "            frameCount = 0; #reset alarm timer when eyes open again\n",
    "            \n",
    "    currentFrame += 1\n",
    "        \n",
    "    #Display the camera feed, press x to close program\n",
    "    cv2.imshow(\"Camera Feed\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"x\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        cam.release()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "# Please note: 'NoneType' object has no attribute 'shape' error message indicates issue with the webcam,\n",
    "#               ensure it is detectable by the computer and fully functioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The below is not part of the program - it is simply the necessary portions of the above code used to test the system on Infra-red images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = cv2.imread('IRtest1.jpg')\n",
    "#frame = cv2.imread('IRtest2.jpg')\n",
    "#frame = cv2.imread('IRtest3.bmp')\n",
    "\n",
    "frame = imutils.resize(frame, width=600)       #Resizes\n",
    "grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Greyscale\n",
    "    \n",
    "#Detect faces within grescale image\n",
    "faces = faceDetector(grey,1)\n",
    "\n",
    "if len(faces) == 0:\n",
    "    print(\"No face detected\")\n",
    "\n",
    "for face in faces:\n",
    "    #Determine facial landmarks for face ROI, then convert co-ords to NumPy array\n",
    "    shape = shapePredictor(grey, face)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    #Draw bounding box around detected face\n",
    "    (x, y, w, h) = face_utils.rect_to_bb(face) #convert dlib rect to openCV bounding box\n",
    "    cv2.rectangle(frame, (x,y), (x+w, y+h), (100,100,100),1)\n",
    "    cv2.putText(frame,\"Driver\", (x-5, y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5, (100,100,100),1)\n",
    "\n",
    "    #Define set of points (from LSP) that constitutes each feature\n",
    "    left_eye = shape[L_eyeStart:L_eyeEnd]\n",
    "    right_eye = shape[R_eyeStart:R_eyeEnd]\n",
    "\n",
    "    #Calculate Eye Aspect Ratio for each eye\n",
    "    left_EAR = calculate_EyeAspectRatio(left_eye)\n",
    "    right_EAR = calculate_EyeAspectRatio(right_eye)\n",
    "    EAR = (left_EAR + right_EAR) / 2.0  #Take Average\n",
    "    cv2.putText(frame, \"EAR: {:.2f}\".format(EAR), (15,310),cv2.FONT_HERSHEY_SIMPLEX,0.85, (100,100,255),2)\n",
    "\n",
    "    #Use OpenCV to draw eye contours\n",
    "    leftEyeHull = cv2.convexHull(left_eye)\n",
    "    rightEyeHull = cv2.convexHull(right_eye)\n",
    "    cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "    cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
    "\n",
    "#Display Image\n",
    "cv2.imshow(\"Camera Feed\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
